{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ST8BpdGA9Dq_",
        "outputId": "ffb52b55-2feb-4c14-c767-62e9ca4a5720"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter path to CSV file (or press Enter for sample data): \n",
            "Loading sample data instead.\n",
            "\n",
            " Original DataFrame below\n",
            "  tshirt_size  color   age\n",
            "0      Medium   Blue  25.0\n",
            "1       Small    Red  30.0\n",
            "2       Large  Green  45.0\n",
            "3      Medium   Blue   NaN\n",
            "4         NaN    Red  22.0\n",
            "5       Small  Green  30.0\n",
            "\n",
            "--- INTERACTIVE PREPROCESSING :-) ---\n",
            "\n",
            "Do you want to run imputation? (y/n): y\n",
            "  Found missing values in: ['tshirt_size', 'age']\n",
            "Strategy for categorical 'tshirt_size' will be 'mode' obviously.\n",
            "  -> Added 'mode' imputer for 'tshirt_size'.\n",
            "Strategy for numeric 'age' (mean/median/mode) [default: mean]: MODE\n",
            "  -> Added 'mode' imputer for 'age'.\n",
            "\n",
            "Do you want to run ordinal encoding? (y/n): n\n",
            "\n",
            "Do you want to run one-hot encoding? (y/n): Y\n",
            "  Available columns for OHE: ['tshirt_size', 'color']\n",
            "  Enter column to one-hot encode (or 'all' or 'done'): ALL\n",
            "  ERROR: Not a valid choice. Choose from: ['tshirt_size', 'color']\n",
            "  Enter column to one-hot encode (or 'all' or 'done'): DONE\n",
            "\n",
            "--- APPLYING TRANSFORMATIONS ---\n",
            "\n",
            "--- Final Processed DataFrame ---\n",
            "  tshirt_size  color   age\n",
            "0      Medium   Blue  25.0\n",
            "1       Small    Red  30.0\n",
            "2       Large  Green  45.0\n",
            "3      Medium   Blue  30.0\n",
            "4      Medium    Red  22.0\n",
            "5       Small  Green  30.0\n",
            "\n",
            " TRANSFORMING NEW DATA (EXAMPLE)\n",
            "\n",
            " New Unseen Data (Original)\n",
            "  tshirt_size   color   age\n",
            "0       Large     Red  50.0\n",
            "1         NaN    Blue   NaN\n",
            "2       Small  Yellow  33.0\n",
            "\n",
            " New Unseen Data (Transformed) \n",
            "  tshirt_size   color   age\n",
            "0       Large     Red  50.0\n",
            "1      Medium    Blue  30.0\n",
            "2       Small  Yellow  33.0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "# using it for path feature working by which user can input in .csv file\n",
        "from pathlib import Path\n",
        "\n",
        "# Core functions for data preprocessing inspired by Sciket-learn fit and transform\n",
        "\n",
        "# for ordinal encoder guys...\n",
        "\n",
        "def fit_ordinal_encoder(df, column, mapping):\n",
        "\n",
        "    #preparing transform input for ordinal encoding here.\n",
        "    if column not in df.columns:\n",
        "        print(f\"Warning: Column '{column}' not found in DataFrame.\")\n",
        "        return None\n",
        "\n",
        "    # storing the column and mapping for later use.\n",
        "    transform_input_ordinal_encoder = {\n",
        "        'type': 'ordinal',\n",
        "        'column_to_encode': column,\n",
        "        'category_mapping': mapping\n",
        "    }\n",
        "    return transform_input_ordinal_encoder\n",
        "\n",
        "def transform_ordinal_encoder(df, transform_input_ordinal_encoder):\n",
        "\n",
        "    #converting categories to ordered numbers here.\n",
        "\n",
        "    df_copy = df.copy()\n",
        "    column = transform_input_ordinal_encoder['column_to_encode']\n",
        "    mapping = transform_input_ordinal_encoder['category_mapping']\n",
        "    new_column_name = f\"{column}_encoded\"\n",
        "\n",
        "    # maping each value to its number after iterating, or NaN if not in the mapping.\n",
        "    encoded_values = []\n",
        "    for value in df_copy[column]:\n",
        "        if value in mapping:\n",
        "            encoded_values.append(mapping[value])\n",
        "        else:\n",
        "            encoded_values.append(np.nan)\n",
        "    df_copy[new_column_name] = encoded_values\n",
        "\n",
        "    return df_copy\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "#for one-hot encoding guys\n",
        "def fit_one_hot_encoder(df, column):\n",
        "\n",
        "    #finding all unique categories in a column here\n",
        "    unique_categories_array = df[column].unique()\n",
        "\n",
        "    # converting the numpy array of categories to a simple list here.\n",
        "    unique_categories_list = []\n",
        "    for category in unique_categories_array:\n",
        "        unique_categories_list.append(category)\n",
        "\n",
        "    # saving the categories for the transform step here.\n",
        "    transform_input_one_hot_encoder = {\n",
        "        'type': 'one_hot', # Added type for our logic\n",
        "        'column_to_encode': column,\n",
        "        'unique_categories': unique_categories_list\n",
        "    }\n",
        "    return transform_input_one_hot_encoder\n",
        "\n",
        "def transform_one_hot_encoder(df, transform_input_one_hot_encoder):\n",
        "\n",
        "    #creating a new column for each unique category here\n",
        "    df_copy = df.copy() # best practices.\n",
        "    column = transform_input_one_hot_encoder['column_to_encode']\n",
        "    unique_categories = transform_input_one_hot_encoder['unique_categories']\n",
        "\n",
        "    # creating a new binary (0 or 1) column for each category here.\n",
        "    for category in unique_categories:\n",
        "        new_column_name = f\"{column}_{category}\"\n",
        "        #converting the boolean output to 0 or 1 and then assigning.\n",
        "        df_copy[new_column_name] = (df_copy[column] == category).astype(int)\n",
        "\n",
        "    # removing the original column.\n",
        "    df_copy = df_copy.drop(columns=[column])\n",
        "    return df_copy\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "#for imputation guys\n",
        "def fit_imputer(df, column, strategy='mean'):\n",
        "    \"\"\"calculating the value to fill missing data based on stratergy input.\"\"\"\n",
        "    if strategy == 'mean':\n",
        "        fill_value = df[column].mean()\n",
        "    elif strategy == 'median':\n",
        "        fill_value = df[column].median()\n",
        "    elif strategy == 'mode':\n",
        "        fill_value = df[column].mode()[0]\n",
        "    # storing the calculated value here.\n",
        "    transform_input_imputer = {\n",
        "        'type': 'impute',\n",
        "        'column_to_impute': column,\n",
        "        'fill_value': fill_value\n",
        "    }\n",
        "    return transform_input_imputer\n",
        "\n",
        "def transform_imputer(df, transform_input_imputer):\n",
        "    \"\"\"filling missing values in a column here.\"\"\"\n",
        "    df_copy = df.copy()\n",
        "    column = transform_input_imputer['column_to_impute']\n",
        "    fill_value = transform_input_imputer['fill_value']\n",
        "    # most important step to impute the calculated value to fill NaNs.\n",
        "    df_copy[column] = df_copy[column].fillna(fill_value)\n",
        "    return df_copy\n",
        "#-------------------------------------------------------------------------------\n",
        "# INTERACTIVE WAY FOR DATA PREPROCESSING GUYS !!!\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "\n",
        "    # lets initialise with none\n",
        "    my_df = None\n",
        "\n",
        "    # asking the user for the file path.\n",
        "    csv_path = input(\"Enter path to CSV file (or press Enter for sample data): \").strip()\n",
        "\n",
        "    # checking if the user entered a path AND if that path end upto real file or not...\n",
        "    if csv_path and Path(csv_path).is_file():\n",
        "        # If both are true,lets load the data from the CSV file.\n",
        "        my_df = pd.read_csv(csv_path)\n",
        "        print(f\"Successfully loaded data from '{csv_path}'.\")\n",
        "    else:\n",
        "        # If the user pressed Enter or the path was bad, print a message.\n",
        "        if csv_path: #if user actually typed a bad path.\n",
        "            print(f\"Error: File not found at '{csv_path}' !!!.\")\n",
        "\n",
        "    # If the above step failed, my_df will still be None.\n",
        "    # In that case, we load the sample data as a fallback.\n",
        "    if my_df is None:\n",
        "        print(\"Loading sample data instead.\")\n",
        "        raw_data = {\n",
        "            'tshirt_size': ['Medium', 'Small', 'Large', 'Medium', np.nan, 'Small'],\n",
        "            'color': ['Blue', 'Red', 'Green', 'Blue', 'Red', 'Green'],\n",
        "            'age': [25, 30, 45, np.nan, 22, 30]\n",
        "        }\n",
        "        my_df = pd.DataFrame(raw_data)\n",
        "\n",
        "    print(\"\\n Original DataFrame below\")\n",
        "    print(my_df)\n",
        "    print(\"\\n--- INTERACTIVE PREPROCESSING :-) ---\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # basically I m building a sort of pipeline\n",
        "    fitted_steps = []\n",
        "    # This list will track columns which already set for ordinal encoding\n",
        "    ordinal_cols_handled = []\n",
        "\n",
        "\n",
        "\n",
        "    # Imputation Step\n",
        "    if input(\"\\nDo you want to run imputation? (y/n): \").lower() == 'y':\n",
        "        numeric_cols = my_df.select_dtypes(include=np.number).columns\n",
        "        cols_with_nan = my_df.columns[my_df.isnull().any()].tolist()\n",
        "\n",
        "        if not cols_with_nan:\n",
        "            print(\"  No columns with missing values found.\")\n",
        "        else:\n",
        "            print(f\"  Found missing values in: {cols_with_nan}\")\n",
        "            for col in cols_with_nan:\n",
        "                if col in numeric_cols:\n",
        "                    strategy = input(f\"Strategy for numeric '{col}' (mean/median/mode) [default: mean]: \").lower()\n",
        "                    if strategy not in ['median', 'mode']:\n",
        "                        strategy = 'mean'\n",
        "                else:\n",
        "                    print(f\"Strategy for categorical '{col}' will be 'mode' obviously.\")\n",
        "                    strategy = 'mode'\n",
        "\n",
        "                # function called here\n",
        "                step_config = fit_imputer(my_df, col, strategy)\n",
        "                # I m adding it in my pipeline.\n",
        "                fitted_steps.append(step_config)\n",
        "\n",
        "                print(f\"  -> Added '{strategy}' imputer for '{col}'.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Ordinal Encoding Step\n",
        "    if input(\"\\nDo you want to run ordinal encoding? (y/n): \").lower() == 'y':\n",
        "        object_cols = my_df.select_dtypes(include=['object']).columns\n",
        "        print(f\"  Available categorical columns: {object_cols.tolist()}\")\n",
        "\n",
        "        while True:\n",
        "            col = input(\"  Enter a column name for ordinal encoding (or 'done'): \")\n",
        "            if col.lower() == 'done':\n",
        "                break\n",
        "            if col not in object_cols:\n",
        "                print(f\"  ERROR: Column '{col}' is not a categorical column.\")\n",
        "                continue\n",
        "\n",
        "            unique_vals = my_df[col].dropna().unique()\n",
        "            print(f\"    Categories in '{col}' are: {unique_vals}\")\n",
        "            mapping = {}\n",
        "            for val in unique_vals:\n",
        "                order = input(f\"    Enter number (0, 1, 2...) for '{val}': \")\n",
        "                mapping[val] = int(order)\n",
        "\n",
        "            print(f\"    Mapping created: {mapping}\")\n",
        "\n",
        "            # function called here\n",
        "            step_config = fit_ordinal_encoder(my_df, col, mapping)\n",
        "            # I m adding it in my pipeline\n",
        "            fitted_steps.append(step_config)\n",
        "\n",
        "            ordinal_cols_handled.append(col)\n",
        "\n",
        "            print(f\"  -> Added ordinal encoder for '{col}'.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # One-Hot Encoding Step\n",
        "    if input(\"\\nDo you want to run one-hot encoding? (y/n): \").lower() == 'y':\n",
        "        object_cols = my_df.select_dtypes(include=['object']).columns\n",
        "        potential_ohe_cols = [col for col in object_cols if col not in ordinal_cols_handled]\n",
        "\n",
        "        if not potential_ohe_cols:\n",
        "            print(\"  No suitable categorical columns left for OHE.\")\n",
        "        else:\n",
        "            print(f\"  Available columns for OHE: {potential_ohe_cols}\")\n",
        "            while True:\n",
        "                col = input(\"  Enter column to one-hot encode (or 'all' or 'done'): \")\n",
        "                if col.lower() == 'done':\n",
        "                    break\n",
        "                if col == 'all':\n",
        "                    for c in potential_ohe_cols:\n",
        "                        step_config = fit_one_hot_encoder(my_df, c)\n",
        "                        fitted_steps.append(step_config)\n",
        "                        print(f\"  -> Added one-hot encoder for '{c}'.\")\n",
        "                    break\n",
        "                if col in potential_ohe_cols:\n",
        "                    step_config = fit_one_hot_encoder(my_df, col)\n",
        "                    fitted_steps.append(step_config)\n",
        "                    print(f\"  -> Added one-hot encoder for '{col}'.\")\n",
        "                else:\n",
        "                    print(f\"  ERROR: Not a valid choice. Choose from: {potential_ohe_cols}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Transformation Step\n",
        "    print(\"\\n--- APPLYING TRANSFORMATIONS ---\")\n",
        "\n",
        "    if not fitted_steps:\n",
        "        print(\"No processing steps were configured. DataFrame is unchanged.\")\n",
        "        df_transformed = my_df.copy()\n",
        "    else:\n",
        "        df_transformed = my_df.copy()\n",
        "\n",
        "        for step in fitted_steps:\n",
        "            step_type = step['type']\n",
        "\n",
        "            if step_type == 'impute':\n",
        "                df_transformed = transform_imputer(df_transformed, step)\n",
        "            elif step_type == 'ordinal':\n",
        "                df_transformed = transform_ordinal_encoder(df_transformed, step)\n",
        "            elif step_type == 'one_hot':\n",
        "                df_transformed = transform_one_hot_encoder(df_transformed, step)\n",
        "\n",
        "        print(\"\\n--- Final Processed DataFrame ---\")\n",
        "        print(df_transformed)\n",
        "\n",
        "    # Using the same instructions for new unseen data\n",
        "    if fitted_steps:\n",
        "        print(\"\\n TRANSFORMING NEW DATA (EXAMPLE)\")\n",
        "\n",
        "        new_data = {\n",
        "            'tshirt_size': ['Large', np.nan, 'Small'],\n",
        "            'color': ['Red', 'Blue', 'Yellow'],\n",
        "            'age': [50, np.nan, 33],\n",
        "        }\n",
        "        new_df = pd.DataFrame(new_data)\n",
        "\n",
        "        print(\"\\n New Unseen Data (Original)\")\n",
        "        print(new_df)\n",
        "\n",
        "        new_df_transformed = new_df.copy()\n",
        "        for step in fitted_steps:\n",
        "            step_type = step['type']\n",
        "            if step_type == 'impute':\n",
        "                new_df_transformed = transform_imputer(new_df_transformed, step)\n",
        "            elif step_type == 'ordinal':\n",
        "                new_df_transformed = transform_ordinal_encoder(new_df_transformed, step)\n",
        "            elif step_type == 'one_hot':\n",
        "                new_df_transformed = transform_one_hot_encoder(new_df_transformed, step)\n",
        "\n",
        "        print(\"\\n New Unseen Data (Transformed) \")\n",
        "        print(new_df_transformed)"
      ]
    }
  ]
}